{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Shapefiles for Sentinel-1 Bursts and Frame Extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# developed 13 Feb 2019, S Lawrie\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import fiona\n",
    "\n",
    "%matplotlib inline \n",
    "# required for correct plotting in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "script_dir = \"~/repo/gamma_insar/S1_FRAME_CREATION\"\n",
    "archive_dir = \"/g/data1/dg9/SENTINEL-1_BURSTS/ARCHIVE_TRACKS\"\n",
    "shp_dir = \"/g/data1/dg9/SENTINEL-1_BURSTS/SHAPEFILES\"\n",
    "\n",
    "orient = \"Descending\"\n",
    "track = 89\n",
    "\n",
    "if orient == \"Ascending\":\n",
    "    orient2 = \"A\"\n",
    "elif orient == \"Descending\":\n",
    "    orient2 = \"D\"\n",
    "\n",
    "burst_name = \"S1_IW_SLC_T%s%s_bursts\" %(track,orient2)\n",
    "scene_name = \"S1_IW_SLC_T%s%s_scenes\" %(track,orient2)\n",
    "input_burst_list = \"%s/%s_track_data/S1_IW_SLC_T%s%s_burst-metadata\" %(archive_dir,orient,track,orient2)\n",
    "\n",
    "burst_shp = \"%s/%s.shp\" %(shp_dir,burst_name)\n",
    "scene_shp = \"%s/%s.shp\" %(shp_dir,scene_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_shp():\n",
    "    \"Creates shapefiles for each burst in a S1 zip file and a shapefile showing overall extent of scene.\"\n",
    "    \n",
    "    # load archive burst coordinates into a dataframe\n",
    "    df_burst_meta_input = pd.read_csv(input_burst_list, sep=\" \")\n",
    "    \n",
    "    ## Convert coordinates into shapely polygons and put into new dataframe\n",
    "    df_burst_meta = pd.DataFrame([])  # create blank dataframe\n",
    "\n",
    "    # iterate over coordinates and append to blank dataframe\n",
    "    for i, row in df_burst_meta_input.iterrows():\n",
    "        mission = row[0]\n",
    "        mode = row[1]\n",
    "        prod_type = row[2]\n",
    "        date = row[3]\n",
    "        pass2 = row[4]\n",
    "        polar = row[5]\n",
    "        ab_orbit = row[6]\n",
    "        rel_orbit = row[7]\n",
    "        swath = row[8]\n",
    "        burst_num = row[9]\n",
    "        uniq_prod_id = row[10]\n",
    "        datatake_id = row[11]\n",
    "        res_class = row[12]\n",
    "        proc_level = row[13]\n",
    "        prod_class = row[14]\n",
    "        scene_start = row[15]\n",
    "        scene_stop = row[16]\n",
    "        ipf_vers = row[17]\n",
    "        raw_facil = row[18]\n",
    "        raw_date = row[19]\n",
    "        raw_time = row[20]\n",
    "        raw_start = row[21]\n",
    "        raw_stop = row[22]\n",
    "        az_time = row[23]\n",
    "        angle = row[24]\n",
    "        delta_angle = row[25]    \n",
    "        ul = Point(row[26], row[27])\n",
    "        ur = Point(row[28], row[29])\n",
    "        lr = Point(row[30], row[31])\n",
    "        ll = Point(row[32], row[33])                  \n",
    "        xml_file = row[34]\n",
    "        grid_dir = row[35]\n",
    "        zip_file = row[36]\n",
    "        pointList = [ul, ur, lr, ll]\n",
    "        poly = Polygon([[p.x, p.y] for p in pointList]) # creates shapely polygon\n",
    "        df_temp1 =  gpd.GeoDataFrame([[mission,mode,prod_type,date,pass2,polar,ab_orbit,rel_orbit,swath,\n",
    "                                       burst_num,uniq_prod_id,datatake_id,res_class,proc_level,prod_class,\n",
    "                                       scene_start,scene_stop,ipf_vers,raw_facil,raw_date,raw_time,raw_start,\n",
    "                                       raw_stop,az_time,angle,delta_angle,xml_file,grid_dir,zip_file,poly]],\n",
    "                          columns = ['Mission','Mode','ProdType','Date','Pass','Polar','AbOrbit','RelOrbit',\n",
    "                                     'Swath','BurstNum','UniqProdID','DatatakeID','ResClass','ProcLevel',\n",
    "                                     'ProdClass','SceneStart','SceneStop','IPFVers','RawFacil','RawDate',\n",
    "                                     'RawTime','RawStart','RawStop','AzTime','Angle','DeltaAngle','XMLFile',\n",
    "                                     'GridDir','ZipFile','Extent'],\n",
    "                          geometry='Extent')\n",
    "        df_burst_meta = df_burst_meta.append(df_temp1, ignore_index=True)    \n",
    "    \n",
    "    ## Consolidate rows (merge dual polarisation details to single entry) and put into new dataframe\n",
    "    df_burst_final = pd.DataFrame([])  # create blank dataframe\n",
    "\n",
    "    zips = df_burst_meta.ZipFile.unique()\n",
    "    zip_list = zips.tolist()\n",
    "    swaths = df_burst_meta.Swath.unique()\n",
    "    swath_list = swaths.tolist()\n",
    "    \n",
    "    for x in zip_list:\n",
    "        zip_rows = df_burst_meta.loc[df_burst_meta['ZipFile'] == x]\n",
    "    \n",
    "        for y in swath_list:\n",
    "            swath_rows = zip_rows.loc[zip_rows['Swath'] == y]\n",
    "            burst_nums = swath_rows.BurstNum.unique()\n",
    "            burst_list = burst_nums.tolist()\n",
    "        \n",
    "            for z in burst_list:\n",
    "                rows = swath_rows.loc[swath_rows['BurstNum'] == z]\n",
    "\n",
    "                # if dual polarisation, merge details into single entry\n",
    "                num_rows = rows.shape[0]\n",
    "                if num_rows == 2:\n",
    "                    polar1 = rows.iloc[0]['Polar']\n",
    "                    polar2 = rows.iloc[1]['Polar']\n",
    "                    new_polar = \"%s,%s\" %(polar1,polar2)\n",
    "                    row = rows.iloc[0].copy()\n",
    "                    row.loc['Polar'] = new_polar # replace polar value\n",
    "                    df_burst_final = df_burst_final.append(row)  \n",
    "                else:\n",
    "                    df_burst_final = df_burst_final.append(rows)  \n",
    "                \n",
    "    # re-order columns to original order                \n",
    "    df_burst_final = df_burst_final[rows.columns]\n",
    "    \n",
    "    # convert to geopandas dataframe\n",
    "    df_burst_final2 = gpd.GeoDataFrame(df_burst_final, geometry='Extent')\n",
    "    \n",
    "    ## Create shapefile of bursts\n",
    "    df_burst_final2.crs = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "    df_burst_final2.to_file(burst_shp, driver='ESRI Shapefile')\n",
    "    \n",
    "    ## Create shapefile of scene extent (merge bursts)\n",
    "    merged = df_burst_final2.drop(columns=['Swath','BurstNum','AzTime','Angle','DeltaAngle','XMLFile']) # remove unnecessary column\n",
    "    merged = merged.dissolve(by='ZipFile')\n",
    "    merged.reset_index(level=0, inplace=True) \n",
    "    merged.crs = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\"\n",
    "    merged.to_file(scene_shp, driver='ESRI Shapefile')\n",
    "\n",
    "    #return df_burst_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_shp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
