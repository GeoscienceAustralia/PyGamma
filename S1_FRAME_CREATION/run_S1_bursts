#!/bin/bash

display_usage() {
    echo ""
    echo "*******************************************************************************"
    echo "* run_S1_bursts: Scrapes Sentinel-1 metadata from the Regional Copernicus     *"
    echo "*                archive. Calculates burst corner coordinates for each file   *"
    echo "*                so scenes can be automatically selected to create new scene  *"
    echo "*                stacks using GA's Sentinel-1 framing system.                 *"
    echo "*                                                                             *"
    echo "* input:  [config_file]   S1 burst config file                                *"
    echo "*                                                                             *"
    echo "* author: Sarah Lawrie @ GA       13/02/2019, v1.0                            *"
    echo "*******************************************************************************"
    echo -e "Usage: run_S1_bursts [config_file]"
    }

if [ $# -lt 1 ]
then
    display_usage
    exit 1
fi

config_file=$1

# Load generic variables
source ~/repo/gamma_insar/S1_FRAME_CREATION/S1_burst_functions $config_file
variables

cd $proj_dir

mkdir -p $processing_dir $zip_dir $burst_dir $ind_burst_dir $pbs_dir $shp_dir


## Get list of zip files currently in the Sentinel-1 archive
if [ $create_zip_list == 'yes' ]; then
    cd $pbs_dir
    job=s1_zip_list
    echo \#\!/bin/bash > $job
    echo \#\PBS -l other=gdata1 >> $job
    echo \#\PBS -l walltime=05:00:00 >> $job
    echo \#\PBS -l mem=10GB >> $job
    echo \#\PBS -l ncpus=1 >> $job
    echo \#\PBS -l wd >> $job
    echo \#\PBS -q express >> $job
    echo ~/repo/gamma_insar/S1_FRAME_CREATION/create_S1_zipfile_list.bash $proj_dir/$config_file >> $job
    chmod +x $job
    qsub $job 
## Extract metadata for each zip file and calculate burst corner coordinates
elif [ $extract_metadata == 'yes' ]; then
    # split zip lists
    mkdir -p $split_dir
    cd $list_dir
    split -l 5000 $zip_list $split_name
    mv $split_name* $split_dir
    cd $split_dir
    ls $split_name* > $split_list

    # create PBS jobs for extracting burst metadata
    cd $pbs_dir

    while read list; do
	part=`echo $list | cut -d '_' -f 6`
	job="bursts_"$part
	echo \#\!/bin/bash > $job
	echo \#\PBS -lother=gdata1 >> $job
	echo \#\PBS -l walltime=12:00:00 >> $job
	echo \#\PBS -l mem=5GB >> $job
	echo \#\PBS -l ncpus=1 >> $job
	echo \#\PBS -l wd >> $job
	echo \#\PBS -q normal >> $job
	echo ~/repo/gamma_insar/S1_FRAME_CREATION/extract_S1_bursts_metadata.bash $proj_dir/$config_file $split_dir/$list >> $job
	chmod +x $job
	qsub $job
    done < $split_list

    echo "Archive tracks last updated on "$date > $proj_dir/LAST_UPDATE

## Create archive lists for selecting scenes for frames 
elif [ $create_archive == 'yes' ]; then
    input_files=$burst_dir/"input_S1_"$mode"_"$type"_list_"*".burst-metadata"
    merged_file=$burst_dir/"S1_"$mode"_"$type"_"$date".burst-metadata"

    cd $burst_dir

    # merge lists into single file
    ls $input_files > list
    while read file; do
	cat $file >> temp
    done < list
    rm -rf list

    # remove repeated headers
    sed '1!{/^Mission/ d;}' temp > $merged_file
    rm -rf temp
    header=`head -n 1 $merged_file`

    # move input lists
    mkdir -p burst_metadata_lists
    mv $input_files burst_metadata_lists

    ## Split list by pass value
    echo "Ascending" > pass_names
    echo "Descending" >> pass_names
    rm -rf pass_list

    while read pass; do
	awk -v var="$pass" -F' ' '$5 == var { print }' $merged_file > $mode"_"$type"_"$pass"_burst-metadata"
        ls $mode"_"$type"_"$pass"_burst-metadata" >> pass_list
        mkdir -p $archive_dir/$pass"_track_data"
    done < pass_names

    ## Split pass files by track for frame archive
    while read file; do
	pass=`echo $file | cut -d '_' -f 3`
        if [ $pass == "Ascending" ]; then 
	    pass1=A
	elif [ $pass == "Descending" ]; then
	    pass1=D
	fi
	awk '{ a[$8]++ } END { for (b in a) { print b } }' $file > $pass"_tracks"
        while read track; do
	    echo $header > "S1_"$mode"_"$type"_T"$track$pass1"_burst-metadata"
            awk -v var="$track" -F' ' '$8 == var { print }' $mode"_"$type"_"$pass"_burst-metadata" >> "S1_"$mode"_"$type"_T"$track$pass1"_burst-metadata"
            mv "S1_"$mode"_"$type"_T"$track$pass1"_burst-metadata" $archive_dir/$pass"_track_data"
        done < $pass"_tracks"
	rm -rf $pass"_tracks"
    done < pass_list
    rm -rf pass_list

    rm -rf track_file_lists
    while read pass; do
	cd $archive_dir/$pass"_track_data"
	ls * > $pass"_list"
	echo $pass"_list" >> $burst_dir/track_file_lists
	cd ../
    done < pass_names
    cd $burst_dir
    rm -rf pass_names

    # Generate python Dataframes for future use in frame data selection
    echo ""
    echo ""
    echo "*********************************"
    echo ""
    echo "Now need to run Jupyter notebook: '' on the VDI to create dataframes for each track."
    echo "    These dataframes are used when selecting scenes for a particular frame."
    echo ""
    echo "*********************************"

## Generate shapefiles of burst extents and overall scene extents
elif [ $create_shp == 'yes' ]; then
    echo ""
    echo ""
    echo "*********************************"
    echo ""
    echo "To create shapefiles of bursts and scene extents for each archive track, need to run Jupyter notebook: ''  on the VDI."
    echo ""
    echo "*********************************"
    echo ""
fi

